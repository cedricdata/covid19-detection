\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{tikz}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{xcolor}

\def\code#1{\texttt{#1}}

\usepackage[top=2cm, bottom=2cm, left=2cm, right=2cm]{geometry}

\pdfminorversion=4

\makeatletter
\addto\captionsfrench{\def\tablename{{\scshape Tableau}}}
\makeatother

\setlength{\parskip}{0.5em}

\begin{document}


\renewcommand{\thepage}{}
% \include{PagesCouv/pg}`

\renewcommand{\thepage}{\arabic{page}}
\setcounter{page}{1}

% ==================================================================
% DIFFÉRENTS LISTES
% table des matières générale
\tableofcontents
\newpage
\section{Contexte et objectifs}

Depuis son apparition à la fin de l'année 2019, la COVID-19 (maladie à coronavirus 2019) continue à faire des dégâts dans le monde entier, sur le plan sanitaire et économique. Le diagnostic tôt de cette maladie reste, jusqu'à l'instant, un des meilleurs moyens pour la lutte contre sa propagation. 

Dans le cadre du développement de moyens de détection rapides et sûrs de la maladie, l'objectif de ce projet est de créer une intelligence artificielle capable de détecter la présence de la COVID-19 chez un patient à partir d'une radiographie pulmonaire. Cette technique constituera un des moyens les plus rapides et les moins chers pour le diagnostique de cette maladie.

Pour développer cette intelligence artificielle, nous nous baserons principalement sur des techniques de réseaux de neurones, et plus particulièrement sur les réseaux de neuronnes convolutifs (CNN). Ces techniques ont montrées leurs efficacités pour le traitement et la classification des images.

L'entraînement de ces algorithmes de machine learning se base sur un jeu de données constitué de milliers de radiographies pulmonaires, ce sont images radiographiques pour trois types de patients : des cas positifs à la COVID-19, des cas normaux, mais aussi des images radiographiques de pneumonies virales (autres que la COVID-19). 

L'objectif de ce travail est donc d'entraîner, à partir du jeu de données que nous disposons, une intelligence artificielle capable de distinguer les trois cas (COVID-19, normal et viral). Pour atteindre cet objectif, nous distinguons principalement deux grandes étapes :

\begin{itemize}
    \item La première étape consiste à l'exploration, l'analyse et la visualisation de données. Cette étape permettra de bien examiner le format et la qualité des données, de voir si il y a des biais dans ces données, etc.
    \item La deuxième étape consiste à mettre en place des algorithmes de classifications qui se basent sur les réseaux de neurones. Plusieurs algorithmes, plus ou moins complexes, seront par la suite testés et évalués. 
\end{itemize}
\newpage
\section{Données}

Les données exploitées dans ce travail sont des images de ragiographies pulmonaires, disponibles dans le site kaggle (https://www.kaggle.com/tawsifurrahman/covid19-radiography-database). Ces images sont regroupées en trois classes : COVID-19, normal et viral-pneumonia, pour des personnes qui sont respectivement atteintes en COVID-19, qui ont des poumons normaux, et qui sont atteintes de pneumonie virale.  

\subsection{Nombre d'images par classe}

Le jeu de données que nous utilisons est un jeu de données équilibré entre les trois classes. La figure~\ref{fig:nb_classes}, qui montre le nombre d'images pour chacune des trois classes, permet d'illustrer cet équilibre. 

\begin{figure}[htbp]
\centering
\includegraphics[width=12cm]{nombre_classes.png}
\caption{Nombre d'images par classe}
\label{fig:nb_classes}
\end{figure}

\subsection{Taille et encodage des images}
En termes de format de données, les images exploitées dans ce projet sont différents par deux aspets :
\begin{itemize}
    \item Nombre de pixels : le nombre de pixels suivant les deux directions varie d'une image à l'autre;
    \item et encodage : bien que les images exploitées sont tous en niveau de gris visuellement, certaines sont encodées en niveau de gris et d'autres sont en RGB. 
\end{itemize}

La figure~\ref{fig:im_size_enc} montre des tableaux qui regroupent, pour chacune des trois classes,le nombre d'images par type d'encodage et par nombre de pixels suivant les deux dimensions.

\begin{figure}[htbp]
  \centering
  \subfigure[COVID-19] {
    \includegraphics[width=9cm]{covid_size.PNG}
    \label{fig:covid}
  }
  \subfigure[Normal] {
    \includegraphics[width= 9cm]{normal_size.PNG}
    \label{fig:normal}
  }
  \subfigure[Pneumonie virale] {
    \includegraphics[width= 9cm]{VP_size.PNG}
    \label{fig:Pneumonie-virale}
  }
  \caption{Pour chaque classe : nombre d'images par type d'encodage et par nombre de pixels suivant les deux dimensions.}
  \label{fig:im_size_enc}
\end{figure}

\section{Analyse et statistiques sur les images}
L'objectif de cette partie est d'analyser les radiographies, afin d'analyser les différences entre les images, et de détecter des biais en cas d'existence.

\begin{figure}[htbp]
\centering
\includegraphics[width=8cm]{COVID-19 (366).png}
\caption{Exemple d'une ragiographie COVID-19}
\label{fig:Radio_COV}
\end{figure}

\subsection{Première analyse visuelle}

Une première analyse visuelle est effectuée en parcourant des images pour les trois classes. Nous observons, sur quelques images, la présence de certains appareils médicaux de mesures, de forme de fils électriques. \textbf{Ces appareils sont présents dans plus d'images de la COVID-19 que pour les autres classes, ce qui peut créer un biais lors de la classification}.  


\subsection{Statistiques sur les images}

Afin d'analyser la répartition des niveaux de gris, nous allons analyser la distribution de la moyenne et de l'écart-type de ces niveaux de gris dans les images de chacune des classes. La figure~\ref{fig:Histos_gray_level} montre la distribution des moyennes et écart-types pour les trois classes. Nous constatons que :
\begin{itemize}
\item La dispersion des moyennes et des écart-types des niveaux de gris est importante. Cette dispersion est plus accentuée pour les images de types COVID-19 et Viral Pneumonia.
\item Contrairement aux autres images, les images de type COVID-19 ont tendance à avoir une moyenne plus élevée et un écart-type plus faible. Dans ce qui suit, nous allons trouver la cause de cette différence.
 \end{itemize}

\begin{figure}[htbp]
\centering
\includegraphics[width=14cm]{Histos_gray_level.png}
\caption{Distribution des moyennes et écart-types pour les trois classes.}
\label{fig:Histos_gray_level}
\end{figure}

\subsection{Filtrage des pixels les moins pertinents}
Nous proposons de filtrer les pixels les moins pertinents pour la classification des images. Nous utilisons pour cela la classe \code{SelectPercentile} de \code{Sklearn.feature\_selection}. La figure~\ref{fig:filtrage} montre un filtrage des pixels en utilisant différents pourcentages de pixels filtrés. Dans les six images présentées dans la figure, les pixels blancs correspondent aux pixels filtrés.
\begin{figure}[htbp]
\centering
\includegraphics[width=18cm]{Filtrage.png}
\caption{Filtrage des pixels les moins pertinents}
\label{fig:filtrage}
\end{figure}

Légitimement, nous pensions que les bords des radiographies étaient peu porteurs d'informations.
Cependant, dans la figure~\ref{fig:filtrage}, les bords verticaux de l'image ne sont toujours pas éliminés, même avec un paramétrage fixé à 70 \%.
Nous verrons que dans le paragraphe suivant que cela est dû à un biais sur les images.

\subsection{Biais sur les images de type COVID-19}
Une analyse poussée des images a permis d'identifier un deuxième biais (autre que le biais des équipements médicaux) : les images de type COVID-19 contiennent moins de bords noires, ce qui relève d'un pré-traitement de ces images en effectuant un zoom. Nous avons pu remarquer ce biais en appliquant deux modèles de visualisation d'images : le modèle Isomap et le modèle TSNE. Le résultat de visualisation de ces deux modèles sont présentés dans le fichier \code{datavisualisation.ipynb} .

\begin{figure}[htbp]
  \centering
  \subfigure[COVID-19] {
    \includegraphics[width=5cm]{COVID-19 (1).png}
    \label{fig:covid1}
  }
  \subfigure[COVID-19] {
    \includegraphics[width=5cm]{COVID-19 (20).png}
    \label{fig:covid2}
  }
  \subfigure[COVID-19] {
    \includegraphics[width=5cm]{COVID-19 (60).png}
    \label{fig:covid3}
  }
  \subfigure[Normal] {
    \includegraphics[width= 5cm]{NORMAL (1).png}
    \label{fig:normal1}
  }
  \subfigure[Normal] {
    \includegraphics[width= 5cm]{NORMAL (20).png}
    \label{fig:normal2}
  }
  \subfigure[Normal] {
    \includegraphics[width= 5cm]{NORMAL (60).png}
    \label{fig:normal3}
  }
  \subfigure[Pneumonie virale] {
    \includegraphics[width= 5cm]{Viral Pneumonia (1).png}
    \label{fig:PV1}
  }
    \subfigure[Pneumonie virale] {
    \includegraphics[width= 5cm]{Viral Pneumonia (20).png}
    \label{fig:PV2}
  }
  \subfigure[Pneumonie virale] {
    \includegraphics[width= 5cm]{Viral Pneumonia (60).png}
    \label{fig:PV3}
  }
  \caption{Comparaison d'images prises au hasard parmi les trois classes.}
  \label{fig:comp_vis}
\end{figure}


Ce biais est cohérent avec ce que nous avons observé pour le filtrage des pixels les moins pertinents (figure~\ref{fig:filtrage}) et dans les distributions (figure~\ref{fig:Histos_gray_level}) :
\begin{itemize}
    \item Les bords verticaux des images ne sont pas éliminés lors du filtrage (figure~\ref{fig:filtrage}), car ils participent fortement à distinguer les images de type COVID-19 des autres images.
    \item Dans les distributions (figure~\ref{fig:Histos_gray_level}), les images de COVID-19 ont des moyennes plus élevées et des écart-types plus faibles, ce qui est un effet de l'absence des bords noirs. Cette absence induit une augumentation du niveau de gris moyen, et une diminution de l'hétérogénéité de l'image et donc de son écart-type de niveau de gris.
\end{itemize}


\subsection{Bilan}

La visualisation et l'analyse des données nous a permis de constater que les images de type COVID-19 diffèrent des autres images par deux aspects : 
\begin{itemize}
    \item La présence plus fréquente de certains appareils médicaux de mesures, de forme de fils électriques;
    \item et l'absence de bords noirs verticaux, résultant probablement d'un zoom effectué par les émetteurs de ces images.
\end{itemize}

Ces caractéristiques risque d'induire en erreur un modèle prédictif, qui se baserait en une partie sur une reconnaissance liée à celle-ci.

Il est possible de corriger la deuxième différence, en effectuant une opération de pré-traitement des images avant de les utiliser pour l'entraînement des modèles. Cette opération consiste à éliminer les bords noirs verticaux sur toutes les radiographies. Ainsi, le modèle se concentrera mieux sur les différences de caractéristiques aux niveaux des poumons.

\section{Modélisation}

Dans cette partie, nous proposons différents modèles pour la classification des images. Ces modèles se basent sur les réseaux de neuronnes denses et convolutifs.

Les différentes modélisations que nous avons testé dans ce projet sont les suivants :
\begin{itemize}
\item Modélisation 1: CNN Lenet.
\item Modélisation 2: CNN personnalisé
\item Modélisation 3: Transfer Learning avec EfficientNetB5
\item Modélisation 4: Modèle hybride avec InceptionV3 et Xgboost.
\item Modélisation 5: VGG16 avec augmentation d'image.
\end{itemize}

Avant de rentrer dans les détails des modèles et les résultats qu'ils donnent, il convient de décrire d'abord le pré-traitement réalisé aux images et la métrique qui sera utilisée pour l'évaluation des modèles.

\subsection{Pré-traitement des images}

\paragraph{Traitement des bords verticaux noires} 
Nous avons remarqué, dans ce qui précède, l'existence d'un biais induit par la présence de bords noirs verticaux. Pour remédier à ce problème, l'idée que nous proposons consiste à réaliser, sur les images de type normal et pneumonie virale, un «zoom» sur les radiographie NORMAL et PNEUMONIE. Pour cela, nous procédons par l'élimination des bords latéraux, inférieurs et supérieurs, afin de se focaliser sur l'information utile, les poumons. Les radiographies sont donc  tronquées de 10\% sur les parties hautes, basses et latérales.

\paragraph{Redimensionnement et normalisation des images} 
Un traitement est ensuite nécessaire pour avoir des images avec une même taille. Ceci est nécessaire pour l'entraînement des modèles. La taille choisie pour tous les images est de 256X256 pixels.

Pour un entrainement meilleur, tous les images ont été normalisées, et ceci en divisant pour chaque pixel son niveau de gris par le niveau de gris maximal qui est de 255.

\subsection{Métriques et sorties des modèles}

\paragraph{Fonction de pertes}
La fonction de perte est la valeur que l'algorithme cherchera à minimiser. Dans notre cas, nous utilisons la fonction \code{categorical\_crossentropy} qui est adaptée à un cas de classification pour plusieurs classes. 

\paragraph{Métrique}
La métrique qui nous intéresse est la précision \code{accuracy}. Elle correspond au pourcentage des bons prédictions sur l'ensemble des prédictions

\paragraph{Sortie des modèles}
La sortie des modèles correspond à la probabilité d'une image d'appartenir à chacune des trois classes. Par la suite, nous attribuons à l'image la classe qui a la probabilité la plus élevée.



\subsection{Modèle LeNet}
Cette première modélisation fait appel à une architecture basée sur "LeNet", un réseau de neurones convolutif, caractérisé par une alternance de couche de convolution et de pooling, permettant l'extraction des caractéristiques des radiographies. La classification est assurée par une couche dense de réseau de neurones connectés.

\subsection{Modèle personnalisée}

Cette deuxième modélisation consiste à un modèle personnalisé par l'équipe, caractérisé par une alternance de couche de convolution et de pooling, permettant l'extraction des caractéristiques des radiographies. La classification est assurée par une couche dense de réseau de neurones connectés.

\subsection{EfficientNetB5}

Cette troisième modélisation est basé sur le principe du transfer learning, qui consiste à utiliser un modèle pré-entrainé sur des centaines de milliers d'image. Le modèle pré-entrainé choisi est EfficientNetB5, il permet l'extraction des caractéristiques des radiographies. La classification est assurée par une couche dense de réseau de neurones connectés.

\subsection{InceptionV3}
Cette quatrième modélisation combine les techniques de deep learning et de machine learning "classique". Un modèle pré-entrainé, InceptionV3, est utilisé pour extraire les caractéristiques des radiographies et un XGBoostClassifier est utilisé pour opérer la classification en sortie du modèle pré-entrainé.

\subsection{VGG16 avec augmentation d'image}
Cette dernière modélisation utilise la technique d'augmentation d'image qui permet d'enrichir le jeu de données et de réduire le phénomène d'overfitting. VGG16, un modèle pré-entrainé, est utlisé pour extraire les caractéristiques des radiographies. La classification est assurée par une couche dense de réseau de neurones connectés.

\subsection{Résultats des différents modèles}

\subsection{Bilan}

\section{Conclusion}

\end{document}
